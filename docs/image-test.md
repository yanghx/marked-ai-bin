# Trae + 国产4大开源模型AI编程对比，Deepseek暂时落后

[](https://juejin.cn/user/3087084378402445/posts)

在完成 MiniMax M2 测试后，在**2025年11月底，** 继续测试几个国产开源模型。

测试内容，还是从0到1创建10个页面的商城站点；工具则借助免费的更开放的 Trae 来测试。

这次参与测试的除了 MiniMax M2，还有 Kimi K2、GLM 4.6、Deepseek V3.1 terminus。

## Deepseek 评价

经过测试，Deepseek 的表现暂时落后，毕竟发布时间是最久的一个了。

![模型-deepseek.jpg](./assets/img_09e23afa_1.webp)

测试的成品跟上个月的 IDE 测试的成品相似度很高，估计之前大家用的都是 Deepseek 吧。

站点的完成度一般。有头无尾：Header 部分已实现，但 Footer 的站点地图、版权信息等缺失。图片尺寸问题、详情页过于简单、首页产品卡片混乱。

优点有：

- 手机版兼容可用。
- 修复 bug 能力不错：使用 JavaScript 转 TypeScript 时出现20多个问题，但修复过程相对顺畅。


![微信图片_20251124213107_242_4.jpg](./assets/img_4a941c6f_1.webp)

缺点有：

- 项目架构简单，仅包含页面、组件和样式三个文件夹。
- 后续需要大量修改。
- 最大问题是 MCP 操作能力一般，无法操作脚本生成项目，而是通过生成 package.json 方式，好在智力水平不错，出错少。


## Kimi K2 评价

Kimi K2 宣传太好，一开始我对它期望挺高的。但是开发过程中问题较多，智能程度在本次测试中排名倒数第二。

![模型-kimi-k2.jpg](./assets/img_ba5ca493_1.webp)

一开始，发现它一直在写 HTML 和 JavaScript，全部页面写完才来补 CSS，我就觉得大事不妙了。出来的效果果然不理想。

最后修复页面样式问题，也花费了很多时间，依然没法兼容手机。

![k2-修复样式.png](./assets/img_7b64f9cb_1.webp)

还有就是虽然使用了 Typescript，完成之后，居然没有验证。20多个问题，修改时间较长，相比其他模型信心不足。

另外，不知道为何触发了英文，后续我没纠正，一直给我飚英文。

优点也有，对比 Deepseek，它能调用命令行工具，项目结构有基本的设计：区分了 UI 组件和 Layout 组件。

总体而言，还是不太放心把工作交给 Kimi。

## MiniMax M2 评价

亚军给到这次没有重复测试 MiniMax M2。

![模型-MiniMax-M2.jpg](./assets/img_ce2adb56_1.webp)

整体而言，站点的完成度优秀。

令人惊喜的是，一开始用的是 Javascript，转成 Typescript 之后，同样出现了 20多个问题，但是修复过程比 Kimi 要顺畅、要快，很少出现 Kimi 那样来回修改的情况。

另外虽然样式的兼容一般，但是一句话就修复了。

所以，它的优点是修复 bug 比较精准、比较快。

![微信图片_20251124214355_245_4.png](./assets/img_4b1cf5da_1.webp)

它除了能调用命令行工具，能给出项目结构图。项目整体的结构也优于其他模型。

Trae 提供的 MiniMax M2 服务响应较慢，如果是同样的资源分配，可能其消耗的资源比较大。

## GLM 4.6 评价

这次的冠军要给到 GLM 4.6，有些出乎意料的低调选手。

![模型-GLM4.6.jpg](./assets/img_9ec92726_1.webp)

印象比较深的是在其调用命令行工具创建时，我选错了一个项。导致无法用 Vite 创建，他也能很快的改用 npm create 重新创建项目。

![glm4.6修复ts.png](./assets/img_ee0d0896_1.webp)

项目跑起来后，初始只有10多个 TypeScript 错误，远优于其他模型。

对 bug 的修复速度、精准度我觉得和 Mini Max M2 不相伯仲。令我惊喜的是，在指出顶部菜单未适配手机端后，直接实现了抽屉菜单效果。可见 GLM 4.6 对样式的理解会更到位。

基于这三点，还是把本次的冠军给了 GLM 4.6。

项目结构上，略逊色于 Mini Max M2，但组件也有区分 Layout，样式独立，类型定义独立。优点是有模拟数据也有API，后期要对接后端也方便。

## 总结与展望

这次的评测，可以总结为一下的对比表格：

| 模型 | 完成度 | 命令行调用能力 | 项目结构 | 修复bug能力 | 兼容性 |
| --- | --- | --- | --- | --- | --- |
| Deepseek V3.1 Terminus | 一般 | 弱 | 简单 | 相对顺畅 | 手机版兼容可用 |
| Kimi K2 | 良好 | 一般 | 一般 | 信心不足，修改时间较长 | 无法兼容手机 |
| MiniMax M2 | 优秀 | 一般 | 优秀 | 修复过程顺畅快速 | 样式兼容一般但易修复 |
| GLM 4.6 | 优秀 | 强 | 优秀 | 修复速度快，精准 | 适配手机端，实现抽屉菜单 |

可以看到，相对其他模型有针对的 Coding 进行了优化，Deepseek 的目标似乎不在于此。所以目前落后也属正常。

而 Mini Max M2 和 GLM 4.6 的优秀表现，至少可以在前端领域放心使用了。他们并不比 Claude Sonnet 差。

同时，我们也不能静态地看待大模型，仅一个月差异，模型就有很大改进。

比如，上个月国产模型为赶上 Claude 4.5 而高兴，本月 Gemini 3 Pro 一骑绝尘，功能完成度远超其他模型。

新的目标已经出现，大模型提供商们还需继续努力~